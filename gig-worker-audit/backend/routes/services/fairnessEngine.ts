// backend/services/fairnessEngine.ts

/**
 * @typedef {Object} AuditResult
 * @property {number} fairnessScore A numerical score between 0.0 (least fair) and 1.0 (most fair).
 * @property {number} [missingAmount] The calculated difference between total and sum of known components.
 * @property {boolean} [penaltyMismatch] True if penalty exceeds a defined percentage of the total earnings.
 * @property {boolean} [ratingIssue] True if a significant rating drop is detected between recent records.
 * @property {string} [explanation] A human-readable summary of the audit findings, often generated by an LLM.
 */
type AuditResult = {
  fairnessScore: number;
  missingAmount?: number;
  penaltyMismatch?: boolean;
  ratingIssue?: boolean;
  explanation?: string;
};

// --- Mocked LLM Call (to show integration point) ---
// Assume this function exists and uses the AI_API_KEY
const callLLMForExplanation = async (data: any, auditResult: AuditResult): Promise<string> => {
    // In a real implementation, load the prompt template from ai/prompts/fairness_explain.prompt.md
    // and instruct the LLM (Gemini/GPT) to generate a concise, human-friendly explanation
    // based on the parsed data and the rules triggered in auditResult.

    const score = Math.round(auditResult.fairnessScore * 100);

    let explanation = `The earnings audit resulted in a Fairness Score of ${score}%.`;

    if (auditResult.missingAmount && auditResult.missingAmount > 0.01) {
        explanation += ` There is a significant unexplained difference of ${auditResult.missingAmount.toFixed(2)} between the total earnings and the sum of base, bonus, and other specified components.`;
    }
    if (auditResult.penaltyMismatch) {
        explanation += ` A large penalty of ${(data.penalties || []).reduce((s: number, p: any) => s + (p.amount || 0), 0).toFixed(2)} was applied, which exceeds the threshold of 20% of total earnings.`;
    }
    if (auditResult.ratingIssue) {
        explanation += ` A recent rating drop was detected, which may indicate a platform-side issue or a potential de-prioritization risk.`;
    }

    return explanation.trim();
};
// --- End Mocked LLM Call ---


/**
 * Core business logic service for auditing earnings data against fairness heuristics.
 */
export const fairnessEngine = {
  /**
   * Runs a series of rule-based checks on the parsed earnings data and computes a fairness score.
   *
   * @param {any} parsedData Structured data from parserService.
   * @param {any} [context] Optional context (e.g., user's historical averages, platform-specific rules).
   * @returns {Promise<AuditResult>} The computed fairness score and detailed findings.
   */
  async auditEarnings(parsedData: any, context: any = {}): Promise<AuditResult> {
    const result: AuditResult = { fairnessScore: 1.0 }; // Start at 1.0 (perfectly fair)
    const total = parsedData.total ?? 0;
    const components = (parsedData.basePay ?? 0) + (parsedData.bonus ?? 0) + (parsedData.distancePay ?? 0);
    const totalPenalty = (parsedData.penalties || []).reduce((s: number, p: any) => s + (p.amount || 0), 0);

    try {
      // 1. Rule: Missing Amount Check (Components vs. Total)
      // Calculate missing amount (Total - Components + Penalties). Use a small epsilon for floating point safety.
      // We expect: total ≈ components - totalPenalty
      // Therefore, the difference (which we interpret as 'missing') should be near zero.
      const expectedTotal = components - totalPenalty;
      // We check the absolute difference between the reported total and the expected total from components.
      const difference = total - expectedTotal;

      // Only track positive difference as 'missing' (underpayment/unexplained fee). Use tolerance of 0.1
      const missing = Math.max(0, difference - 0.1);
      result.missingAmount = missing;

      // Severity 1: If missing amount is > 5% of total, reduce score significantly
      const missingPercentage = total > 0 ? missing / total : 0;
      if (missingPercentage > 0.05) {
        result.fairnessScore -= 0.4; // Major deduction
      }

      // 2. Rule: Penalty Threshold Check
      // If the total penalty amount is too high relative to gross earnings (components)
      const penaltyPercentageOfGross = components > 0 ? totalPenalty / components : 0;
      // Threshold: 20% of the non-deducted components
      result.penaltyMismatch = penaltyPercentageOfGross > 0.20;

      if (result.penaltyMismatch) {
        result.fairnessScore -= 0.3; // Moderate deduction
      }

      // 3. Rule: Recent Rating Drop Detection
      const ratings = parsedData.ratings || [];
      result.ratingIssue = false;
      if (ratings.length >= 2) {
        // Compare the most recent rating to the one before it
        const last = ratings[ratings.length - 1].rating;
        const prev = ratings[ratings.length - 2].rating;

        // Arbitrary threshold: drop of 0.3 points or more (e.g., 4.9 -> 4.5)
        if (prev && last && (prev - last) > 0.3) {
          result.ratingIssue = true;
          result.fairnessScore -= 0.2; // Minor deduction
        }
      }

      // Clamp score between 0 and 1
      result.fairnessScore = Math.max(0, Math.min(1, result.fairnessScore));

      // 4. Explanation Generation
      if (process.env.AI_API_KEY) {
        // Use the LLM to synthesize the findings into a clear, non-technical explanation.
        result.explanation = await callLLMForExplanation(parsedData, result);
      } else {
        // Fallback explanation for environments without AI key
        result.explanation = `
          AUTOMATED AUDIT REPORT:
          Score: ${Math.round(result.fairnessScore * 100)}%.
          Missing Funds: ${result.missingAmount && result.missingAmount > 0.01 ? `₹${result.missingAmount.toFixed(2)} unexplained.` : "None detected."}
          Penalty Check: ${result.penaltyMismatch ? `Excessive penalty detected (₹${totalPenalty.toFixed(2)}).` : "Penalty acceptable."}
          Rating Drop: ${result.ratingIssue ? "Recent rating decline detected." : "No significant rating change."}
        `.trim().replace(/\s+/g, ' ');
      }

      return result;

    } catch (e) {
      console.error("Fairness engine encountered a critical error:", e);
      // Return a 0 score on critical error
      return { fairnessScore: 0, explanation: "Critical internal error during fairness audit." };
    }
  },
};