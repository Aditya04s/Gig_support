// backend/services/fairnessEngine.ts

/**
 * @typedef {Object} AuditResult
 * @property {number} fairnessScore A numerical score between 0.0 (least fair) and 1.0 (most fair).
 * @property {number} [missingAmount] The calculated difference between total and sum of known components.
 * @property {boolean} [penaltyMismatch] True if penalty exceeds a defined percentage of the total earnings.
 * @property {boolean} [ratingIssue] True if a significant rating drop is detected between recent records.
 * @property {string} [explanation] A human-readable summary of the audit findings, often generated by an LLM.
 */
type AuditResult = {
  fairnessScore: number;
  missingAmount?: number;
  penaltyMismatch?: boolean;
  ratingIssue?: boolean;
  explanation?: string;
};

// --- LLM Call Placeholder (Replaces Mocked Function) ---
const callLLMForExplanation = async (data: any, auditResult: AuditResult): Promise<string> => {
    const score = Math.round(auditResult.fairnessScore * 100);

    // --- TODO: INSERT REAL LLM API CALL LOGIC HERE ---
    // 1. Use the prompt template from ai/prompts/fairness_explain.prompt.md
    // 2. Instruct the LLM (e.g., Gemini) to generate a concise, human-friendly explanation
    //    based on the parsed data and the rules triggered in auditResult.

    if (process.env.AI_API_KEY) {
        // Placeholder for real LLM call
        console.warn("LLM Explanation call not implemented. Using fallback.");
    }
    
    // Fallback explanation logic (now the primary for the MVP)
    let explanation = `The earnings audit resulted in a Fairness Score of ${score}%.`;

    if (auditResult.missingAmount && auditResult.missingAmount > 0.01) {
        explanation += ` There is a significant unexplained difference of ₹${auditResult.missingAmount.toFixed(2)} between the total earnings and the sum of base, bonus, and other specified components. This discrepancy requires further investigation.`;
    }
    if (auditResult.penaltyMismatch) {
        const totalPenalty = (data.penalties || []).reduce((s: number, p: any) => s + (p.amount || 0), 0);
        explanation += ` A large penalty of ₹${totalPenalty.toFixed(2)} was applied, which exceeds the acceptable threshold (20% of gross earnings). This is flagged as a potential non-compliance issue.`;
    }
    if (auditResult.ratingIssue) {
        explanation += ` A low recent rating was detected (below 4.5), which may indicate a risk of de-prioritization by the platform.`;
    }
    if (score === 100) {
        explanation = "The earnings record appears to be fully compliant with the established fairness rules. No significant discrepancies or non-compliant penalties were detected.";
    }

    return explanation.trim();
};
// --- End LLM Call Placeholder ---


/**
 * Core business logic service for auditing earnings data against fairness heuristics.
 */
export const fairnessEngine = {
  /**
   * Runs a series of rule-based checks on the parsed earnings data and computes a fairness score.
   *
   * @param {any} parsedData Structured data from parserService.
   * @param {any} [context] Optional context (e.g., user's historical averages, platform-specific rules).
   * @returns {Promise<AuditResult>} The computed fairness score and detailed findings.
   */
  async auditEarnings(parsedData: any, context: any = {}): Promise<AuditResult> {
    const result: AuditResult = { fairnessScore: 1.0 }; // Start at 1.0 (perfectly fair)
    const total = parsedData.total ?? 0;
    // Calculate components: basePay + bonus + distancePay
    const components = (parsedData.basePay ?? 0) + (parsedData.bonus ?? 0) + (parsedData.distancePay ?? 0);
    const totalPenalty = (parsedData.penalties || []).reduce((s: number, p: any) => s + (p.amount || 0), 0);

    try {
      // 1. Rule: Missing Amount Check (Components vs. Total)
      // Expected Total = Gross Components - Total Penalty
      // Difference = Reported Total - Expected Total
      const expectedTotal = components - totalPenalty;
      const difference = total - expectedTotal;

      // Only track positive difference as 'missing' (underpayment/unexplained fee). Use tolerance of 0.1
      const missing = Math.max(0, difference - 0.1); 
      result.missingAmount = missing;

      // Severity 1: If missing amount is > 5% of total, reduce score significantly
      const missingPercentage = total > 0 ? missing / total : 0;
      if (missingPercentage > 0.05) {
        result.fairnessScore -= 0.4; // Major deduction
      }

      // 2. Rule: Penalty Threshold Check
      // If the total penalty amount is too high relative to gross earnings (components)
      const penaltyPercentageOfGross = components > 0 ? totalPenalty / components : 0;
      // Threshold: 20% of the non-deducted components
      result.penaltyMismatch = penaltyPercentageOfGross > 0.20;

      if (result.penaltyMismatch) {
        result.fairnessScore -= 0.3; // Moderate deduction
      }

      // 3. Rule: Recent Rating Check (Simplified for MVP single snapshot)
      const ratings = parsedData.ratings || [];
      result.ratingIssue = false;
      
      if (ratings.length >= 1) {
        const lastRating = ratings[ratings.length - 1].rating;

        // Arbitrary threshold: flag if the last known rating is below 4.5
        if (lastRating && lastRating < 4.5) {
          result.ratingIssue = true;
          result.fairnessScore -= 0.2; // Minor deduction
        }
        // NOTE: The previous logic for rating drop (comparing two ratings) requires historical data
        // and is disabled for this MVP single-screenshot flow.
      }

      // Clamp score between 0 and 1
      result.fairnessScore = Math.max(0, Math.min(1, result.fairnessScore));

      // 4. Explanation Generation
      // Call the LLM (or the fallback function) to synthesize findings.
      result.explanation = await callLLMForExplanation(parsedData, result);

      return result;

    } catch (e) {
      console.error("Fairness engine encountered a critical error:", e);
      // Return a 0 score on critical error
      return { fairnessScore: 0, explanation: "Critical internal error during fairness audit." };
    }
  },
};